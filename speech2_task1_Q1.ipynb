{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76a9e05f258e46c29e98ccd6c8c1170c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3909e29c88141a29bdeb36cb9571022",
              "IPY_MODEL_c51ff59e719d4a3ebdaecc8785322db1"
            ],
            "layout": "IPY_MODEL_64ffaf0089be46a0bb0f199edd55dbdb"
          }
        },
        "e3909e29c88141a29bdeb36cb9571022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a622f699796d4182981c71df8bab48be",
            "placeholder": "​",
            "style": "IPY_MODEL_dca721c6137b480ea8bfe283430d33d7",
            "value": "0.019 MB of 0.019 MB uploaded\r"
          }
        },
        "c51ff59e719d4a3ebdaecc8785322db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6cd4fdbdd7247f3ac47fd850de802d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2c4fa8b0e574f1b8cc8901195aee032",
            "value": 1
          }
        },
        "64ffaf0089be46a0bb0f199edd55dbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a622f699796d4182981c71df8bab48be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca721c6137b480ea8bfe283430d33d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6cd4fdbdd7247f3ac47fd850de802d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c4fa8b0e574f1b8cc8901195aee032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11759ff1b62c435681adc3eed826281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d83d4674c1144d3c94d6c7ca20414b43",
              "IPY_MODEL_b576fed4525e4cf78c57e12b91a42522"
            ],
            "layout": "IPY_MODEL_473e546068c2495ca1d2ce9da673f7b5"
          }
        },
        "d83d4674c1144d3c94d6c7ca20414b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051b1630ab644470970a0885adef0089",
            "placeholder": "​",
            "style": "IPY_MODEL_e753479e9371471dbf6e06554c5d9596",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "b576fed4525e4cf78c57e12b91a42522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f21f4162e5c4bc3a1b62f858159fc83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8555a18c362948dd90ce5ae909db7905",
            "value": 1
          }
        },
        "473e546068c2495ca1d2ce9da673f7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051b1630ab644470970a0885adef0089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e753479e9371471dbf6e06554c5d9596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f21f4162e5c4bc3a1b62f858159fc83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8555a18c362948dd90ce5ae909db7905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGXWbh3rxxek"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "!pip install speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysakDY87zLW0",
        "outputId": "1b030f77-0ad1-4c2c-e118-ff09ac513260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb login c07f9b9363b1d2736cf24c01a4747e245909f2cc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zGn4m-9dCiQ",
        "outputId": "3d11ecbd-4aab-4c94-af80-5e57dc807990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from zipfile import ZipFile\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio as ta\n",
        "import wandb\n",
        "\n",
        "from transformers import Wav2Vec2FeatureExtractor, WavLMForXVector, UniSpeechSatForXVector, HubertForSequenceClassification\n",
        "from speechbrain.inference.speaker import EncoderClassifier"
      ],
      "metadata": {
        "id": "vIhPwQEvza25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(\"/content/drive/MyDrive/FinalSpeech/VoxCeleb1_subset.tar-tron’s MacBook Pro.gz\") as tar:\n",
        "  tar.extractall(\"/content/\")\n",
        "\n",
        "!mv -v /content/VoxCeleb1_subset/test/* /content/VoxCeleb1_subset/dev/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D8KAYqmJPhg",
        "outputId": "6ba3c520-29bc-4149-b525-d13b55b43f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10270' to '/content/VoxCeleb1_subset/dev/id10270': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10271' to '/content/VoxCeleb1_subset/dev/id10271': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10272' to '/content/VoxCeleb1_subset/dev/id10272': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10273' to '/content/VoxCeleb1_subset/dev/id10273': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10274' to '/content/VoxCeleb1_subset/dev/id10274': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10275' to '/content/VoxCeleb1_subset/dev/id10275': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10276' to '/content/VoxCeleb1_subset/dev/id10276': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10278' to '/content/VoxCeleb1_subset/dev/id10278': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10279' to '/content/VoxCeleb1_subset/dev/id10279': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10280' to '/content/VoxCeleb1_subset/dev/id10280': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10281' to '/content/VoxCeleb1_subset/dev/id10281': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10282' to '/content/VoxCeleb1_subset/dev/id10282': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10283' to '/content/VoxCeleb1_subset/dev/id10283': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10284' to '/content/VoxCeleb1_subset/dev/id10284': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10285' to '/content/VoxCeleb1_subset/dev/id10285': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10286' to '/content/VoxCeleb1_subset/dev/id10286': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10287' to '/content/VoxCeleb1_subset/dev/id10287': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10288' to '/content/VoxCeleb1_subset/dev/id10288': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10290' to '/content/VoxCeleb1_subset/dev/id10290': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10291' to '/content/VoxCeleb1_subset/dev/id10291': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10292' to '/content/VoxCeleb1_subset/dev/id10292': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10293' to '/content/VoxCeleb1_subset/dev/id10293': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10294' to '/content/VoxCeleb1_subset/dev/id10294': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10295' to '/content/VoxCeleb1_subset/dev/id10295': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10296' to '/content/VoxCeleb1_subset/dev/id10296': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10297' to '/content/VoxCeleb1_subset/dev/id10297': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10298' to '/content/VoxCeleb1_subset/dev/id10298': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10299' to '/content/VoxCeleb1_subset/dev/id10299': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10300' to '/content/VoxCeleb1_subset/dev/id10300': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10301' to '/content/VoxCeleb1_subset/dev/id10301': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10302' to '/content/VoxCeleb1_subset/dev/id10302': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10303' to '/content/VoxCeleb1_subset/dev/id10303': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10304' to '/content/VoxCeleb1_subset/dev/id10304': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10305' to '/content/VoxCeleb1_subset/dev/id10305': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10306' to '/content/VoxCeleb1_subset/dev/id10306': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10307' to '/content/VoxCeleb1_subset/dev/id10307': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10308' to '/content/VoxCeleb1_subset/dev/id10308': Directory not empty\n",
            "mv: cannot move '/content/VoxCeleb1_subset/test/id10309' to '/content/VoxCeleb1_subset/dev/id10309': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cosine_similarity = nn.CosineSimilarity(dim=-1)"
      ],
      "metadata": {
        "id": "X-D7lO7MOgGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root_dir, txt_file, max_frames=32000):\n",
        "    self.root_dir = root_dir\n",
        "    self.txt_file = txt_file\n",
        "    self.max_frames = max_frames\n",
        "    self.data = self.read_file()\n",
        "\n",
        "  def read_file(self):\n",
        "    data = []\n",
        "    with open(self.txt_file, 'r') as fil:\n",
        "      for line in fil:\n",
        "        label, first, second = line.strip().split()\n",
        "\n",
        "        second_path = os.path.join(self.root_dir, second)\n",
        "        first_path = os.path.join(self.root_dir, first)\n",
        "\n",
        "        if os.path.exists(first_path) :\n",
        "          if os.path.exists(second_path):\n",
        "              data.append((label, first, second))\n",
        "\n",
        "    return data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def process_sample(self, path):\n",
        "    filename, _ = os.path.splitext(path)\n",
        "    path = filename + \".wav\"\n",
        "    file_path = os.path.join(self.root_dir, path)\n",
        "\n",
        "    wav, sample_rate = ta.load(file_path)\n",
        "    num_frames = wav.shape[1]\n",
        "\n",
        "    if num_frames >= self.max_frames:\n",
        "      wav = wav[:, :self.max_frames]\n",
        "    else:\n",
        "      pad_size = self.max_frames - num_frames\n",
        "      wav = F.pad(wav, (0, pad_size), value=0)\n",
        "\n",
        "    return wav, sample_rate\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label, first_path, second_path = self.data[idx]\n",
        "    first_tensor, first_sample_rate = self.process_sample(first_path)\n",
        "    second_tensor, second_sample_rate = self.process_sample(second_path)\n",
        "\n",
        "    first_tensor = first_tensor.squeeze(0)\n",
        "    second_tensor = second_tensor.squeeze(0)\n",
        "    label = torch.tensor(np.array(int(label)))\n",
        "\n",
        "    return first_tensor, second_tensor, label"
      ],
      "metadata": {
        "id": "O16QPeMKzlII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_eer(labels, preds):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(labels, preds, pos_label=1)\n",
        "    eer = np.min(np.abs(fpr - (1 - tpr)))\n",
        "    return eer"
      ],
      "metadata": {
        "id": "OVIfVksG1YTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, extractor, cos_sim):\n",
        "    model.eval()\n",
        "    total_eer = 0\n",
        "\n",
        "    for batch_idx, (wav1, wav2, label) in enumerate(test_loader):\n",
        "      wav1 = wav1.to(device)\n",
        "      wav2 = wav2.to(device)\n",
        "\n",
        "      with torch.inference_mode():\n",
        "          audio1 = extractor(wav1.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.squeeze(0).to(device)\n",
        "          audio2 = extractor(wav2.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.squeeze(0).to(device)\n",
        "\n",
        "          embeddings1 = F.normalize(model(input_values=audio1).embeddings,dim=-1).cpu()\n",
        "          embeddings2 = F.normalize(model(input_values=audio2).embeddings,dim=-1).cpu()\n",
        "\n",
        "          similarity = torch.sigmoid(cos_sim(embeddings1, embeddings2))\n",
        "          eer = compute_eer(label, similarity)\n",
        "          total_eer += eer\n",
        "\n",
        "          if batch_idx % 50 == 0:\n",
        "            print(f\"{batch_idx+1}/{len(test_loader)} EER: {eer}\")\n",
        "\n",
        "    total_eer = total_eer / len(test_loader)\n",
        "    return total_eer"
      ],
      "metadata": {
        "id": "93qBmCSC5jnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ecapa(classifier, test_dataloader, cos_sim):\n",
        "    total_eer = 0\n",
        "    for batch_idx, (wav1, wav2, label) in enumerate(test_dataloader):\n",
        "      wav1 = wav1.to(device)\n",
        "      wav2 = wav2.to(device)\n",
        "\n",
        "      with torch.inference_mode():\n",
        "          embeddings1 = (F.normalize(classifier.encode_batch(wav1),dim=-1)).cpu()\n",
        "          embeddings2 = (F.normalize(classifier.encode_batch(wav2),dim=-1)).cpu()\n",
        "\n",
        "          similarity = torch.sigmoid(cos_sim(embeddings1, embeddings2))\n",
        "          eer = compute_eer(label, similarity)\n",
        "          total_eer += eer\n",
        "\n",
        "          if batch_idx % 50 == 0:\n",
        "            print(f\"{batch_idx+1}/{len(test_dataloader)} EER: {eer}\")\n",
        "\n",
        "    total_eer = total_eer / len(test_dataloader)\n",
        "\n",
        "    return total_eer"
      ],
      "metadata": {
        "id": "ncPBTpAAfNSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VoxCeleb1-H"
      ],
      "metadata": {
        "id": "LMVuW0OZl6l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Speech Assignment Task 1\", name=\"Voxceleb1-H\")"
      ],
      "metadata": {
        "id": "qz12kRQUhPyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "d2db4896c3394339bf22924f515ef3b2"
          ]
        },
        "outputId": "73ee01fb-f5ce-46a8-9e23-5072dc7780b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:dh67mwlv) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2db4896c3394339bf22924f515ef3b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Voxceleb1-H</strong> at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/dh67mwlv' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/dh67mwlv</a><br/> View project at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240412_132538-dh67mwlv/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:dh67mwlv). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240412_133221-541ohayw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw' target=\"_blank\">Voxceleb1-H</a></strong> to <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d29cf67ac50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file = \"/content/VoxCeleb1_subset/list_test_hard.txt\"\n",
        "wav_dir = \"/content/VoxCeleb1_subset/dev\"\n",
        "\n",
        "vox_test_dataset = CustomDataset(wav_dir, txt_file, 32000)\n",
        "vox_test_loader = DataLoader(vox_test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "QuWXkGUVAxU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Ecapa TDNN"
      ],
      "metadata": {
        "id": "HfZnYo2zgb6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":\"cuda\"} )\n",
        "vox_ecapa_eer = round(evaluate_ecapa(classifier,vox_test_loader,cosine_similarity),4)\n",
        "wandb.log({'ECAPA VOX EER': vox_ecapa_eer})\n",
        "print(f\"Average EER(%): {vox_ecapa_eer * 100}%\")"
      ],
      "metadata": {
        "id": "nGrNFpv5gbKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d526e406-82a0-4dfe-a3e9-173d5bf62d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/152 EER: 0.05726405090137862\n",
            "51/152 EER: 0.011764705882352927\n",
            "101/152 EER: 0.023809523809523767\n",
            "151/152 EER: 0.013785790031813405\n",
            "Average EER(%): 1.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Unispeech-sat-base"
      ],
      "metadata": {
        "id": "zTqPHS53Wq-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = UniSpeechSatForXVector.from_pretrained('microsoft/unispeech-sat-base-sv').to(device)\n",
        "extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/unispeech-sat-base-sv')\n",
        "vox_uni_eer = round(evaluate(model,vox_test_loader,extractor,cosine_similarity),4)\n",
        "wandb.log({f'Unispeech VOX EER': vox_uni_eer})\n",
        "print(f\"Average EER(%): {vox_uni_eer * 100}%\")"
      ],
      "metadata": {
        "id": "e5IxcShDD1eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a52ae5-fba9-4e45-8194-0e59684133e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/unispeech-sat-base-sv were not used when initializing UniSpeechSatForXVector: ['unispeech_sat.encoder.pos_conv_embed.conv.weight_g', 'unispeech_sat.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing UniSpeechSatForXVector from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing UniSpeechSatForXVector from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of UniSpeechSatForXVector were not initialized from the model checkpoint at microsoft/unispeech-sat-base-sv and are newly initialized: ['unispeech_sat.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'unispeech_sat.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/152 EER: 0.04901960784313722\n",
            "51/152 EER: 0.027571580063626727\n",
            "101/152 EER: 0.0019607843137255387\n",
            "151/152 EER: 0.015763546798029493\n",
            "Average EER(%): 2.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Wavlm-base-plus"
      ],
      "metadata": {
        "id": "wjSGbPcvhhZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WavLMForXVector.from_pretrained('microsoft/wavlm-base-plus-sv').to(device)\n",
        "extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
        "vox_wavlm_eer = round(evaluate(model,vox_test_loader,extractor,cosine_similarity),4)\n",
        "wandb.log({f'Wavlm VOX EER': vox_wavlm_eer})\n",
        "print(f\"Average EER(%): {vox_wavlm_eer * 100}\")"
      ],
      "metadata": {
        "id": "esysSeFRHfAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0719e0-8130-4de3-8c46-fd2c326767ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/wavlm-base-plus-sv were not used when initializing WavLMForXVector: ['wavlm.encoder.pos_conv_embed.conv.weight_g', 'wavlm.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing WavLMForXVector from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing WavLMForXVector from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of WavLMForXVector were not initialized from the model checkpoint at microsoft/wavlm-base-plus-sv and are newly initialized: ['wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/152 EER: 0.016194331983805627\n",
            "51/152 EER: 0.0\n",
            "101/152 EER: 0.0\n",
            "151/152 EER: 0.0009852216748768572\n",
            "Average EER(%): 1.7500000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "4rAdfUTTjPB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "76a9e05f258e46c29e98ccd6c8c1170c",
            "e3909e29c88141a29bdeb36cb9571022",
            "c51ff59e719d4a3ebdaecc8785322db1",
            "64ffaf0089be46a0bb0f199edd55dbdb",
            "a622f699796d4182981c71df8bab48be",
            "dca721c6137b480ea8bfe283430d33d7",
            "e6cd4fdbdd7247f3ac47fd850de802d4",
            "e2c4fa8b0e574f1b8cc8901195aee032"
          ]
        },
        "outputId": "aaec6774-8819-4bb7-93f1-1a8adf82a1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76a9e05f258e46c29e98ccd6c8c1170c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ECAPA VOX EER</td><td>▁</td></tr><tr><td>Unispeech VOX EER</td><td>▁</td></tr><tr><td>Wavlm VOX EER</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ECAPA VOX EER</td><td>0.0159</td></tr><tr><td>Unispeech VOX EER</td><td>0.0204</td></tr><tr><td>Wavlm VOX EER</td><td>0.0175</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Voxceleb1-H</strong> at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/541ohayw</a><br/> View project at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240412_133221-541ohayw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kathbath Dataset"
      ],
      "metadata": {
        "id": "KWD_q-PJiIPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project=\"Speech Assignment Task 1\", name=\"Kathbath Dataset\")"
      ],
      "metadata": {
        "id": "Te9y0F4plT2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f0aaa01b-7985-4066-d5b1-6e607e1d610b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240412_135553-t3htmkd4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4' target=\"_blank\">Kathbath Dataset</a></strong> to <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d2969ab19f0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs(\"/content/kb_test_hi/\", exist_ok=True)\n",
        "# with ZipFile(\"/content/drive/MyDrive/FinalSpeech/kb_test_hi.zip\", \"r\") as kb:\n",
        "#   kb.extractall(\"/content/kb_test_hi/\")"
      ],
      "metadata": {
        "id": "mWQao58SiSZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # drive_folder = \"/content/drive/MyDrive/\"\n",
        "# # kb_val_dir = \"/content/kb_val_hi/wav\"\n",
        "# kb_test_dir = \"/content/kb_test_hi\"\n",
        "# kb_test_pairs = \"/content/drive/MyDrive/FinalSpeech/kb_test_pairs.txt\"\n",
        "# kb_val_pairs = \"/content/drive/MyDrive/FinalSpeech/kb_valid_pairs.txt\""
      ],
      "metadata": {
        "id": "D3RpT6poiFCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kb_test_dataset = CustomDataset(kb_test_dir, kb_test_pairs, 32000)\n",
        "# kb_test_loader = DataLoader(kb_test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "6EKh5VqaiV76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Ecapa TDNN"
      ],
      "metadata": {
        "id": "79wsUqVVjATi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":\"cuda\"} )\n",
        "# kb_ecapa_eer = round(evaluate_ecapa(classifier,kb_test_loader,cosine_similarity),4)\n",
        "# wandb.log({'ECAPA KB EER': kb_ecapa_eer})\n",
        "# print(f\"Average EER(%): {kb_ecapa_eer * 100}%\")"
      ],
      "metadata": {
        "id": "iYunBfd1jATj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62525ba8-90e8-409b-96c0-ff5fa44b7113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/782 EER: 0.03503503503503508\n",
            "51/782 EER: 0.03251231527093601\n",
            "101/782 EER: 0.03125\n",
            "151/782 EER: 0.0\n",
            "201/782 EER: 0.0029325513196481467\n",
            "251/782 EER: 0.01379310344827589\n",
            "301/782 EER: 0.03174603174603169\n",
            "351/782 EER: 0.0\n",
            "401/782 EER: 0.005882352941176505\n",
            "451/782 EER: 0.03323558162267837\n",
            "501/782 EER: 0.007843137254901933\n",
            "551/782 EER: 0.042510121457489836\n",
            "601/782 EER: 0.0021645021645022022\n",
            "651/782 EER: 0.04926108374384236\n",
            "701/782 EER: 0.03503503503503502\n",
            "751/782 EER: 0.0029325513196481467\n",
            "Average EER(%): 2.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Unispeech-sat-base"
      ],
      "metadata": {
        "id": "gSw73gKXjATj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = UniSpeechSatForXVector.from_pretrained('microsoft/unispeech-sat-base-sv').to(device)\n",
        "# extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/unispeech-sat-base-sv')\n",
        "# kb_uni_eer = round(evaluate(model,kb_test_loader,extractor,cosine_similarity),4)\n",
        "# wandb.log({f'Unispeech KB EER': kb_uni_eer})\n",
        "# print(f\"Average EER(%): {kb_uni_eer * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d484f0a9-3fbd-4288-eac3-3ea056133995",
        "id": "ENPsMRWhjATj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/unispeech-sat-base-sv were not used when initializing UniSpeechSatForXVector: ['unispeech_sat.encoder.pos_conv_embed.conv.weight_g', 'unispeech_sat.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing UniSpeechSatForXVector from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing UniSpeechSatForXVector from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of UniSpeechSatForXVector were not initialized from the model checkpoint at microsoft/unispeech-sat-base-sv and are newly initialized: ['unispeech_sat.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'unispeech_sat.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/782 EER: 0.007881773399014746\n",
            "51/782 EER: 0.0\n",
            "101/782 EER: 0.007936507936507908\n",
            "151/782 EER: 0.011904761904761918\n",
            "201/782 EER: 0.02346041055718473\n",
            "251/782 EER: 0.014778325123152636\n",
            "301/782 EER: 0.04984093319194066\n",
            "351/782 EER: 0.03743842364532024\n",
            "401/782 EER: 0.03910068426197455\n",
            "451/782 EER: 0.03125\n",
            "501/782 EER: 0.015873015873015817\n",
            "551/782 EER: 0.03128054740957964\n",
            "601/782 EER: 0.0\n",
            "651/782 EER: 0.014778325123152747\n",
            "701/782 EER: 0.06206206206206211\n",
            "751/782 EER: 0.014170040485829982\n",
            "Average EER(%): 2.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Wavlm-base-plus"
      ],
      "metadata": {
        "id": "rwSRerPQjATj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = WavLMForXVector.from_pretrained('microsoft/wavlm-base-plus-sv').to(device)\n",
        "# extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
        "# kb_wavlm_eer = round(evaluate(model,kb_test_loader,extractor,cosine_similarity),4)\n",
        "# wandb.log({f'Wavlm KB EER': kb_wavlm_eer})\n",
        "# print(f\"Average EER(%): {kb_wavlm_eer * 100}\")"
      ],
      "metadata": {
        "id": "Xf298vwGjATk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c573c5-fd00-4b5e-cedf-acf6974b97f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/wavlm-base-plus-sv were not used when initializing WavLMForXVector: ['wavlm.encoder.pos_conv_embed.conv.weight_g', 'wavlm.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing WavLMForXVector from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing WavLMForXVector from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of WavLMForXVector were not initialized from the model checkpoint at microsoft/wavlm-base-plus-sv and are newly initialized: ['wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/782 EER: 0.032032032032031976\n",
            "51/782 EER: 0.025490196078431393\n",
            "101/782 EER: 0.05506883604505636\n",
            "151/782 EER: 0.007881773399014746\n",
            "201/782 EER: 0.051808406647116334\n",
            "251/782 EER: 0.015873015873015872\n",
            "301/782 EER: 0.050980392156862786\n",
            "351/782 EER: 0.033333333333333326\n",
            "401/782 EER: 0.022267206477732837\n",
            "451/782 EER: 0.015873015873015817\n",
            "501/782 EER: 0.009803921568627472\n",
            "551/782 EER: 0.00396825396825401\n",
            "601/782 EER: 0.02502502502502507\n",
            "651/782 EER: 0.007881773399014746\n",
            "701/782 EER: 0.049049049049049054\n",
            "751/782 EER: 0.03125\n",
            "Average EER(%): 2.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "8KJqtATolMKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "11759ff1b62c435681adc3eed826281e",
            "d83d4674c1144d3c94d6c7ca20414b43",
            "b576fed4525e4cf78c57e12b91a42522",
            "473e546068c2495ca1d2ce9da673f7b5",
            "051b1630ab644470970a0885adef0089",
            "e753479e9371471dbf6e06554c5d9596",
            "0f21f4162e5c4bc3a1b62f858159fc83",
            "8555a18c362948dd90ce5ae909db7905"
          ]
        },
        "outputId": "88a349ab-046b-41d8-b302-cbeb78ffa02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11759ff1b62c435681adc3eed826281e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ECAPA KB EER</td><td>▁</td></tr><tr><td>Unispeech KB EER</td><td>▁</td></tr><tr><td>Wavlm KB EER</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ECAPA KB EER</td><td>0.0231</td></tr><tr><td>Unispeech KB EER</td><td>0.0233</td></tr><tr><td>Wavlm KB EER</td><td>0.0246</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Kathbath Dataset</strong> at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201/runs/t3htmkd4</a><br/> View project at: <a href='https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201' target=\"_blank\">https://wandb.ai/kushal1506/Speech%20Assignment%20Task%201</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240412_135553-t3htmkd4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "ZRxNo5OWxTzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/speechbrain/speechbrain.git"
      ],
      "metadata": {
        "id": "Mhkw4EXjmCO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce148d7-02ab-4337-d6a5-835f7b9d5297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'speechbrain'...\n",
            "remote: Enumerating objects: 80014, done.\u001b[K\n",
            "remote: Counting objects: 100% (2785/2785), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1818/1818), done.\u001b[K\n",
            "remote: Total 80014 (delta 1543), reused 1846 (delta 880), pack-reused 77229\u001b[K\n",
            "Receiving objects: 100% (80014/80014), 87.36 MiB | 18.01 MiB/s, done.\n",
            "Resolving deltas: 100% (53270/53270), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from zipfile import ZipFile\n",
        "\n",
        "# # os.makedirs(\"/content/kb_test_hi/\", exist_ok=True)\n",
        "\n",
        "# with ZipFile(\"/content/drive/MyDrive/FinalSpeech/valid.zip\", \"r\") as kb:\n",
        "#   kb.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "5ySfR6WxzIxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r ../content/speechbrain/requirements.txt\n",
        "# !pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5tKQ-ccE9br",
        "outputId": "8508606b-8242-42b5-abfa-af9e39a96d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting black==24.3.0 (from -r ../content/speechbrain/lint-requirements.txt (line 1))\n",
            "  Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/lint-requirements.txt (line 2)) (8.1.7)\n",
            "Collecting flake8==7.0.0 (from -r ../content/speechbrain/lint-requirements.txt (line 3))\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort==5.13.2 (from -r ../content/speechbrain/lint-requirements.txt (line 4))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle==2.11.0 (from -r ../content/speechbrain/lint-requirements.txt (line 5))\n",
            "  Downloading pycodestyle-2.11.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pydoclint==0.4.1 (from -r ../content/speechbrain/lint-requirements.txt (line 6))\n",
            "  Downloading pydoclint-0.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==7.4.0 (from -r ../content/speechbrain/lint-requirements.txt (line 7))\n",
            "  Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yamllint==1.35.1 (from -r ../content/speechbrain/lint-requirements.txt (line 8))\n",
            "  Downloading yamllint-1.35.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: hyperpyyaml>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 7)) (2.0.3)\n",
            "Collecting pre-commit>=2.3.0 (from -r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading pre_commit-3.7.0-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.2/204.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygtrie<3.0,>=2.1 (from -r ../content/speechbrain/requirements.txt (line 9))\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy<1.13.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 11)) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 13)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 14)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.42.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 15)) (4.66.2)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from -r ../content/speechbrain/requirements.txt (line 16)) (4.38.2)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==24.3.0->-r ../content/speechbrain/lint-requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black==24.3.0->-r ../content/speechbrain/lint-requirements.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==24.3.0->-r ../content/speechbrain/lint-requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==24.3.0->-r ../content/speechbrain/lint-requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black==24.3.0->-r ../content/speechbrain/lint-requirements.txt (line 1)) (4.11.0)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8==7.0.0->-r ../content/speechbrain/lint-requirements.txt (line 3))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8==7.0.0->-r ../content/speechbrain/lint-requirements.txt (line 3))\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser-fork>=0.0.5 (from pydoclint==0.4.1->-r ../content/speechbrain/lint-requirements.txt (line 6))\n",
            "  Downloading docstring_parser_fork-0.0.5-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r ../content/speechbrain/lint-requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r ../content/speechbrain/lint-requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r ../content/speechbrain/lint-requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from yamllint==1.35.1->-r ../content/speechbrain/lint-requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml>=0.0.1->-r ../content/speechbrain/requirements.txt (line 3)) (0.18.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->-r ../content/speechbrain/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->-r ../content/speechbrain/requirements.txt (line 7)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->-r ../content/speechbrain/requirements.txt (line 7)) (2024.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading identify-2.5.35-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r ../content/speechbrain/requirements.txt (line 16)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r ../content/speechbrain/requirements.txt (line 16)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->-r ../content/speechbrain/requirements.txt (line 16)) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->-r ../content/speechbrain/requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml>=0.0.1->-r ../content/speechbrain/requirements.txt (line 3)) (0.2.8)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=2.3.0->-r ../content/speechbrain/requirements.txt (line 8))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.8.0->-r ../content/speechbrain/requirements.txt (line 2)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->-r ../content/speechbrain/requirements.txt (line 13)) (1.3.0)\n",
            "Installing collected packages: pygtrie, distlib, virtualenv, pytest, pyflakes, pycodestyle, pathspec, nodeenv, mypy-extensions, mccabe, isort, identify, docstring-parser-fork, cfgv, yamllint, pydoclint, pre-commit, flake8, black\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "Successfully installed black-24.3.0 cfgv-3.4.0 distlib-0.3.8 docstring-parser-fork-0.0.5 flake8-7.0.0 identify-2.5.35 isort-5.13.2 mccabe-0.7.0 mypy-extensions-1.0.0 nodeenv-1.8.0 pathspec-0.12.1 pre-commit-3.7.0 pycodestyle-2.11.0 pydoclint-0.4.1 pyflakes-3.2.0 pygtrie-2.5.0 pytest-7.4.0 virtualenv-20.25.1 yamllint-1.35.1\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/speechbrain/recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py /content/speechbrain/recipes/VoxCeleb/SpeakerRec/hparams/train_ecapa_tdnn.yaml --data_folder=/content/valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lPQt689E1pq",
        "outputId": "3a18496f-feae-4553-c316-9de735bd6920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm23csa011\u001b[0m (\u001b[33mkushal1506\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240412_180514-bw2h4n8i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrare-glade-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kushal1506/FineTune_EPCCA\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kushal1506/FineTune_EPCCA/runs/bw2h4n8i\u001b[0m\n",
            "/content/valid/noise/data.zip exists. Skipping download\n",
            "/content/valid/rir/data.zip exists. Skipping download\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/ecapa_augment/1986\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - 22.2M trainable parameters in SpeakerBrain\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "  0% 0/498 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "numexpr.utils - NumExpr defaulting to 2 threads.\n",
            " 21% 105/498 [01:23<04:12,  1.56it/s, train_loss=15.8]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100% 498/498 [06:09<00:00,  1.35it/s, train_loss=9.91]\n",
            "100% 53/53 [00:05<00:00,  9.19it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.7e-06 to 7.7e-06\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 7.66e-06 - train loss: 9.91 - valid loss: 5.99e-01, valid ErrorRate: 1.19e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ecapa_augment/1986/save/CKPT+2024-04-12+18-11-31+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 498/498 [05:57<00:00,  1.39it/s, train_loss=1.92]\n",
            "100% 53/53 [00:06<00:00,  8.12it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.5e-05 to 1.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 1.53e-05 - train loss: 1.92 - valid loss: 1.87e-01, valid ErrorRate: 4.75e-03\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ecapa_augment/1986/save/CKPT+2024-04-12+18-17-36+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ecapa_augment/1986/save/CKPT+2024-04-12+18-11-31+00\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ███▇▇▆▅▅▅▅▅▄▄▄▄▄▃▃▃▁▃▂▂▂▂▂▂▁▂▂▂▂▂▁▃▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.00853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrare-glade-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kushal1506/FineTune_EPCCA/runs/bw2h4n8i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/kushal1506/FineTune_EPCCA\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240412_180514-bw2h4n8i/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkXKxjoHG75G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}